{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is inspired by the work of CEM (Zarlenga et al. 2022) and CBM (Koh et al. 2020) papers. Please visit their GitHub repositories:\n",
    "[CEM GitHub](https://github.com/mateoespinosa/cem) and [CBM GitHub](https://github.com/yewsiang/ConceptBottleneck).\n",
    "\n",
    "# CBM: oracle model training - V1 (trained on NCF train & NCF test splits)\n",
    "\n",
    "There are four main steps:\n",
    "1. Loading the dataset.\n",
    "2. Initializing a CBM with InceptionV3 vision backbone for the dataset.\n",
    "3. Training the CBM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data\n",
    "\n",
    "The first step is to load the data. The designed CBM class with the PyTorch Lightning Trainer takes in PyTorch DataLoader object.\n",
    "Furthermore, it needs to contain three elements (in the following order):\n",
    "1. the sample image, $\\mathbf{x}$\n",
    "2. the image label, $\\mathbf{y}$\n",
    "3. the concept labels, in binary format, $\\mathbf{c}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#from cub_data_module import *\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "import torchvision.models as models\n",
    "import pytorch_lightning as pl\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys #for Kaggle\n",
    "#sys.path.append(\"/kaggle/usr/lib/cub_data_module_confounded\") #for Kaggle\n",
    "\n",
    "import src.cub_data_module_oracle_v2 as cub_data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _update_config_with_dataset(\n",
    "    config,\n",
    "    train_dl,\n",
    "    n_concepts,\n",
    "    n_tasks,\n",
    "    concept_map,\n",
    "):\n",
    "    config[\"n_concepts\"] = config.get(\n",
    "        \"n_concepts\",\n",
    "        n_concepts,\n",
    "    )\n",
    "    config[\"n_tasks\"] = config.get(\n",
    "        \"n_tasks\",\n",
    "        n_tasks,\n",
    "    )\n",
    "    config[\"concept_map\"] = config.get(\n",
    "        \"concept_map\",\n",
    "        concept_map,\n",
    "    )\n",
    "\n",
    "    task_class_weights = None\n",
    "\n",
    "    if config.get('use_task_class_weights', False):\n",
    "        logging.info(\n",
    "            f\"Computing task class weights in the training dataset with \"\n",
    "            f\"size {len(train_dl)}...\"\n",
    "        )\n",
    "        attribute_count = np.zeros((max(n_tasks, 2),))\n",
    "        samples_seen = 0\n",
    "        for i, data in enumerate(train_dl):\n",
    "            if len(data) == 2:\n",
    "                (_, (y, _)) = data\n",
    "            else:\n",
    "                (_, y, _) = data\n",
    "            if n_tasks > 1:\n",
    "                y = torch.nn.functional.one_hot(\n",
    "                    y,\n",
    "                    num_classes=n_tasks,\n",
    "                ).cpu().detach().numpy()\n",
    "            else:\n",
    "                y = torch.cat(\n",
    "                    [torch.unsqueeze(1 - y, dim=-1), torch.unsqueeze(y, dim=-1)],\n",
    "                    dim=-1,\n",
    "                ).cpu().detach().numpy()\n",
    "            attribute_count += np.sum(y, axis=0)\n",
    "            samples_seen += y.shape[0]\n",
    "        print(\"Class distribution is:\", attribute_count / samples_seen)\n",
    "        if n_tasks > 1:\n",
    "            task_class_weights = samples_seen / attribute_count - 1\n",
    "        else:\n",
    "            task_class_weights = np.array(\n",
    "                [attribute_count[0]/attribute_count[1]]\n",
    "            )\n",
    "    return task_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _generate_dataset_and_update_config(\n",
    "    experiment_config\n",
    "):\n",
    "    if experiment_config.get(\"dataset_config\", None) is None:\n",
    "        raise ValueError(\n",
    "            \"A dataset_config must be provided for each experiment run!\"\n",
    "        )\n",
    "\n",
    "    dataset_config = experiment_config['dataset_config']\n",
    "    logging.debug(\n",
    "        f\"The dataset's root directory is {dataset_config.get('root_dir')}\"\n",
    "    )\n",
    "    intervention_config = experiment_config.get('intervention_config', {})\n",
    "    if dataset_config[\"dataset\"] == \"cub\":\n",
    "        data_module = cub_data_module\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset {dataset_config['dataset']}!\")\n",
    "\n",
    "    train_dl, val_dl, test_dl, imbalance, (n_concepts, n_tasks, concept_map) = \\\n",
    "        data_module.generate_data(\n",
    "            config=dataset_config,\n",
    "            seed=42,\n",
    "            output_dataset_vars=True,\n",
    "            root_dir=dataset_config.get('root_dir', None),\n",
    "        )\n",
    "    # For now, we assume that all concepts have the same\n",
    "    # aquisition cost\n",
    "    acquisition_costs = None\n",
    "    if concept_map is not None:\n",
    "        intervened_groups = list(\n",
    "            range(\n",
    "                0,\n",
    "                len(concept_map) + 1,\n",
    "                intervention_config.get('intervention_freq', 1),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        intervened_groups = list(\n",
    "            range(\n",
    "                0,\n",
    "                n_concepts + 1,\n",
    "                intervention_config.get('intervention_freq', 1),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    task_class_weights = _update_config_with_dataset(\n",
    "        config=experiment_config,\n",
    "        train_dl=train_dl,\n",
    "        n_concepts=n_concepts,\n",
    "        n_tasks=n_tasks,\n",
    "        concept_map=concept_map,\n",
    "    )\n",
    "    return (\n",
    "        train_dl,\n",
    "        val_dl,\n",
    "        test_dl,\n",
    "        imbalance,\n",
    "        concept_map,\n",
    "        intervened_groups,\n",
    "        task_class_weights,\n",
    "        acquisition_costs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "yaml_path = \"data/cub.yaml\" # for local development, might need to use whole path.\n",
    "\n",
    "with open(yaml_path, \"r\") as file:\n",
    "    yaml_config = yaml.safe_load(file)\n",
    "yaml_config[\"shared_params\"][\"dataset_config\"][\"root_dir\"] = \"/kaggle/input/cem-cub2000-filtered/\" #for Kaggle, replace this with locally downloaded folder.\n",
    "yaml_config[\"shared_params\"][\"dataset_config\"][\"num_workers\"] = 4 #change depending on resources available.\n",
    "yaml_config[\"shared_params\"][\"dataset_config\"][\"batch_size\"] = 64 #change depending on resources available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dl, val_dl, test_dl, imbalance, concept_map, intervened_groups, task_class_weights, acquisition_costs = _generate_dataset_and_update_config(yaml_config[\"shared_params\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create the CBM\n",
    "### Step 2.1 Define model for input to concepts\n",
    "We first need to define a architecture that will extract the concepts from the input image.\n",
    "\n",
    "For this, we used a pre-trained InceptionV3 model. We remove the last linear layer and make one that we can use for our task, so it is ready for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def latent_code_generator_model(output_dim=112):\n",
    "    # Load pre-trained InceptionV3\n",
    "    inception = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)\n",
    "\n",
    "    # Remove auxiliary classifier (set to None)\n",
    "    inception.aux_logits = False  # Disable aux_logits\n",
    "    inception.AuxLogits = None  # Delete aux classifier branch\n",
    "\n",
    "    inception.fc = torch.nn.Linear(2048, output_dim)  # Replace classification layer with output_dim\n",
    "\n",
    "    return inception"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: define CBM model.\n",
    "We need to define the following:\n",
    "1. `n_concepts`: the number of concepts in the dataset (112).\n",
    "2. `n_tasks`: the number of output labels in the dataset (200).\n",
    "3. `concept_loss_weight`: the weight to use for the concept prediction loss during training of the CBM. Picked to be the same as the CEM paper.\n",
    "4. `learning_rate` and `optimizer`: to use during training. Optimizer is Adam by default, otherwise SGD.\n",
    "5. `c_extractor_arch`: the model architecture to use for going from the input space to the concepts.\n",
    "6. `c2y_model` and `c2y_layers`: the model architecture to use for going from the concepts to the labels. It can be directly the model, like c_extractor_arch or the layers as a list. We choose to do a simple linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src.utils_cbm import *\n",
    "from src.cbm import ConceptBottleneckModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cbm_model = ConceptBottleneckModel(\n",
    "  n_concepts=112,\n",
    "  n_tasks=200,\n",
    "  concept_loss_weight=yaml_config[\"shared_params\"][\"concept_loss_weight\"],\n",
    "  learning_rate=yaml_config[\"shared_params\"][\"learning_rate\"],\n",
    "  optimizer=\"sgd\", \n",
    "  c_extractor_arch=latent_code_generator_model,\n",
    "  c2y_model=None\n",
    ")\n",
    "#print(cbm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Example of inspection the data manually\n",
    "if False:\n",
    "    file_path = \"/kaggle/input/cem-cub2000-filtered/train.pkl\"\n",
    "\n",
    "    # Load the pickle file\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        train_data = pickle.load(file)\n",
    "\n",
    "    # Print the type of data loaded to understand its structure\n",
    "    #print(type(train_data))\n",
    "    #print(train_data[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train the CBM\n",
    "\n",
    "Let's construct a PyTorch Lightning Trainer object to take care of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\", #or \"cpu\"\n",
    "    devices=\"auto\",\n",
    "    max_epochs=EPOCHS,\n",
    "    check_val_every_n_epoch=5,\n",
    "    logger=False,\n",
    ")\n",
    "\n",
    "trainer.fit(cbm_model, train_dl, val_dl) # Train the model\n",
    "\n",
    "trainer.save_checkpoint(f\"/kaggle/working/cbm_{EPOCHS}.ckpt\") # Save the trainer with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: possible continue training\n",
    "If you want to continue the training, you can do so by calling the trainer again and giving the path to the previous model in the fit(...) call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\", #or \"cpu\"\n",
    "    devices=\"auto\",\n",
    "    max_epochs=EPOCHS,\n",
    "    check_val_every_n_epoch=5,\n",
    "    logger=False,\n",
    ")\n",
    "\n",
    "trainer.fit(cbm_model, train_dl, val_dl, ckpt_path=\"/kaggle/working/cbm_30.ckpt\")  # Train the model starting from the previous checkpoint\n",
    "\n",
    "trainer.save_checkpoint(f\"/kaggle/working/cbm_{EPOCHS}.ckpt\") # Save the trainer with the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: evaluation\n",
    "This will be done in a seperate notebook"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2534241,
     "sourceId": 5140550,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6600121,
     "sourceId": 10658340,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 220467553,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 220470336,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 221777950,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
