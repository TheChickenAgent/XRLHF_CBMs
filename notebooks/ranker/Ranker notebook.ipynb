{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is inspired by the work of CEM (Zarlenga et al. 2022) and CBM (Koh et al. 2020) papers. Please visit their GitHub repositories:\n",
    "[CEM GitHub](https://github.com/mateoespinosa/cem) and [CBM GitHub](https://github.com/yewsiang/ConceptBottleneck).\n",
    "\n",
    "# Ranker: ranker training\n",
    "\n",
    "There are four main steps:\n",
    "1. Loading the dataset.\n",
    "2. Initializing a CBM with InceptionV3 vision backbone for the dataset.\n",
    "3. Load CBMs\n",
    "4. Training the Ranker\n",
    "5. Evaluating"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data\n",
    "\n",
    "The first step is to load the data. The designed CBM class with the PyTorch Lightning Trainer takes in PyTorch DataLoader object.\n",
    "Furthermore, it needs to contain three elements (in the following order):\n",
    "1. the sample image, $\\mathbf{x}$\n",
    "2. the image label, $\\mathbf{y}$\n",
    "3. the concept labels, in binary format, $\\mathbf{c}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:50:55.360548Z",
     "iopub.status.busy": "2025-02-10T15:50:55.360202Z",
     "iopub.status.idle": "2025-02-10T15:50:55.364457Z",
     "shell.execute_reply": "2025-02-10T15:50:55.363454Z",
     "shell.execute_reply.started": "2025-02-10T15:50:55.360518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#from cub_data_module import *\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "import torchvision.models as models\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:50:56.577019Z",
     "iopub.status.busy": "2025-02-10T15:50:56.576740Z",
     "iopub.status.idle": "2025-02-10T15:51:06.267463Z",
     "shell.execute_reply": "2025-02-10T15:51:06.266809Z",
     "shell.execute_reply.started": "2025-02-10T15:50:56.576999Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#import sys #for Kaggle\n",
    "#sys.path.append(\"/kaggle/usr/lib/cub_data_module_confounded\") #for Kaggle\n",
    "\n",
    "import src.cub_data_module as cub_data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:51:09.421018Z",
     "iopub.status.busy": "2025-02-10T15:51:09.420500Z",
     "iopub.status.idle": "2025-02-10T15:51:09.428399Z",
     "shell.execute_reply": "2025-02-10T15:51:09.427470Z",
     "shell.execute_reply.started": "2025-02-10T15:51:09.420990Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _update_config_with_dataset(\n",
    "    config,\n",
    "    train_dl,\n",
    "    n_concepts,\n",
    "    n_tasks,\n",
    "    concept_map,\n",
    "):\n",
    "    config[\"n_concepts\"] = config.get(\n",
    "        \"n_concepts\",\n",
    "        n_concepts,\n",
    "    )\n",
    "    config[\"n_tasks\"] = config.get(\n",
    "        \"n_tasks\",\n",
    "        n_tasks,\n",
    "    )\n",
    "    config[\"concept_map\"] = config.get(\n",
    "        \"concept_map\",\n",
    "        concept_map,\n",
    "    )\n",
    "\n",
    "    task_class_weights = None\n",
    "\n",
    "    if config.get('use_task_class_weights', False):\n",
    "        logging.info(\n",
    "            f\"Computing task class weights in the training dataset with \"\n",
    "            f\"size {len(train_dl)}...\"\n",
    "        )\n",
    "        attribute_count = np.zeros((max(n_tasks, 2),))\n",
    "        samples_seen = 0\n",
    "        for i, data in enumerate(train_dl):\n",
    "            if len(data) == 2:\n",
    "                (_, (y, _)) = data\n",
    "            else:\n",
    "                (_, y, _) = data\n",
    "            if n_tasks > 1:\n",
    "                y = torch.nn.functional.one_hot(\n",
    "                    y,\n",
    "                    num_classes=n_tasks,\n",
    "                ).cpu().detach().numpy()\n",
    "            else:\n",
    "                y = torch.cat(\n",
    "                    [torch.unsqueeze(1 - y, dim=-1), torch.unsqueeze(y, dim=-1)],\n",
    "                    dim=-1,\n",
    "                ).cpu().detach().numpy()\n",
    "            attribute_count += np.sum(y, axis=0)\n",
    "            samples_seen += y.shape[0]\n",
    "        print(\"Class distribution is:\", attribute_count / samples_seen)\n",
    "        if n_tasks > 1:\n",
    "            task_class_weights = samples_seen / attribute_count - 1\n",
    "        else:\n",
    "            task_class_weights = np.array(\n",
    "                [attribute_count[0]/attribute_count[1]]\n",
    "            )\n",
    "    return task_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:51:09.429822Z",
     "iopub.status.busy": "2025-02-10T15:51:09.429582Z",
     "iopub.status.idle": "2025-02-10T15:51:09.446585Z",
     "shell.execute_reply": "2025-02-10T15:51:09.445861Z",
     "shell.execute_reply.started": "2025-02-10T15:51:09.429803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _generate_dataset_and_update_config(\n",
    "    experiment_config\n",
    "):\n",
    "    if experiment_config.get(\"dataset_config\", None) is None:\n",
    "        raise ValueError(\n",
    "            \"A dataset_config must be provided for each experiment run!\"\n",
    "        )\n",
    "\n",
    "    dataset_config = experiment_config['dataset_config']\n",
    "    logging.debug(\n",
    "        f\"The dataset's root directory is {dataset_config.get('root_dir')}\"\n",
    "    )\n",
    "    intervention_config = experiment_config.get('intervention_config', {})\n",
    "    if dataset_config[\"dataset\"] == \"cub\":\n",
    "        data_module = cub_data_module\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset {dataset_config['dataset']}!\")\n",
    "\n",
    "    train_dl, val_dl, test_dl, imbalance, (n_concepts, n_tasks, concept_map) = \\\n",
    "        data_module.generate_data(\n",
    "            config=dataset_config,\n",
    "            seed=42,\n",
    "            output_dataset_vars=True,\n",
    "            root_dir=dataset_config.get('root_dir', None),\n",
    "        )\n",
    "    # For now, we assume that all concepts have the same\n",
    "    # aquisition cost\n",
    "    acquisition_costs = None\n",
    "    if concept_map is not None:\n",
    "        intervened_groups = list(\n",
    "            range(\n",
    "                0,\n",
    "                len(concept_map) + 1,\n",
    "                intervention_config.get('intervention_freq', 1),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        intervened_groups = list(\n",
    "            range(\n",
    "                0,\n",
    "                n_concepts + 1,\n",
    "                intervention_config.get('intervention_freq', 1),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    task_class_weights = _update_config_with_dataset(\n",
    "        config=experiment_config,\n",
    "        train_dl=train_dl,\n",
    "        n_concepts=n_concepts,\n",
    "        n_tasks=n_tasks,\n",
    "        concept_map=concept_map,\n",
    "    )\n",
    "    return (\n",
    "        train_dl,\n",
    "        val_dl,\n",
    "        test_dl,\n",
    "        imbalance,\n",
    "        concept_map,\n",
    "        intervened_groups,\n",
    "        task_class_weights,\n",
    "        acquisition_costs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:51:09.448128Z",
     "iopub.status.busy": "2025-02-10T15:51:09.447926Z",
     "iopub.status.idle": "2025-02-10T15:51:09.483943Z",
     "shell.execute_reply": "2025-02-10T15:51:09.483328Z",
     "shell.execute_reply.started": "2025-02-10T15:51:09.448110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "yaml_path = \"data/cub.yaml\" # for local development, might need to use whole path.\n",
    "\n",
    "with open(yaml_path, \"r\") as file:\n",
    "    yaml_config = yaml.safe_load(file)\n",
    "yaml_config[\"shared_params\"][\"dataset_config\"][\"root_dir\"] = \"/kaggle/input/cem-cub2000-filtered/\" #for Kaggle, replace this with locally downloaded folder.\n",
    "yaml_config[\"shared_params\"][\"dataset_config\"][\"num_workers\"] = 4 #change depending on resources available.\n",
    "yaml_config[\"shared_params\"][\"dataset_config\"][\"batch_size\"] = 64 #change depending on resources available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:51:09.485176Z",
     "iopub.status.busy": "2025-02-10T15:51:09.484924Z",
     "iopub.status.idle": "2025-02-10T15:51:10.994629Z",
     "shell.execute_reply": "2025-02-10T15:51:10.993981Z",
     "shell.execute_reply.started": "2025-02-10T15:51:09.485143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dl, val_dl, test_dl, imbalance, concept_map, intervened_groups, task_class_weights, acquisition_costs = _generate_dataset_and_update_config(yaml_config[\"shared_params\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create the CBM\n",
    "### Step 2.1 Define model for input to concepts\n",
    "We first need to define a architecture that will extract the concepts from the input image.\n",
    "\n",
    "For this, we used a pre-trained InceptionV3 model. We remove the last linear layer and make one that we can use for our task, so it is ready for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:51:10.995870Z",
     "iopub.status.busy": "2025-02-10T15:51:10.995524Z",
     "iopub.status.idle": "2025-02-10T15:51:11.000311Z",
     "shell.execute_reply": "2025-02-10T15:51:10.999458Z",
     "shell.execute_reply.started": "2025-02-10T15:51:10.995836Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def latent_code_generator_model(output_dim=112):\n",
    "    # Load pre-trained InceptionV3\n",
    "    inception = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)\n",
    "\n",
    "    # Remove auxiliary classifier (set to None)\n",
    "    inception.aux_logits = False  # Disable aux_logits\n",
    "    inception.AuxLogits = None  # Delete aux classifier branch\n",
    "\n",
    "    inception.fc = torch.nn.Linear(2048, output_dim)  # Replace classification layer with output_dim\n",
    "\n",
    "    return inception"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: define CBM model.\n",
    "We need to define the following:\n",
    "1. `n_concepts`: the number of concepts in the dataset (112).\n",
    "2. `n_tasks`: the number of output labels in the dataset (200).\n",
    "3. `concept_loss_weight`: the weight to use for the concept prediction loss during training of the CBM. Picked to be the same as the CEM paper.\n",
    "4. `learning_rate` and `optimizer`: to use during training. Optimizer is Adam by default, otherwise SGD.\n",
    "5. `c_extractor_arch`: the model architecture to use for going from the input space to the concepts.\n",
    "6. `c2y_model` and `c2y_layers`: the model architecture to use for going from the concepts to the labels. It can be directly the model, like c_extractor_arch or the layers as a list. We choose to do a simple linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:51:11.001484Z",
     "iopub.status.busy": "2025-02-10T15:51:11.001198Z",
     "iopub.status.idle": "2025-02-10T15:51:11.022400Z",
     "shell.execute_reply": "2025-02-10T15:51:11.021844Z",
     "shell.execute_reply.started": "2025-02-10T15:51:11.001457Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src.utils_cbm import *\n",
    "from src.cbm import ConceptBottleneckModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:51:11.113048Z",
     "iopub.status.busy": "2025-02-10T15:51:11.112864Z",
     "iopub.status.idle": "2025-02-10T15:51:11.130650Z",
     "shell.execute_reply": "2025-02-10T15:51:11.129828Z",
     "shell.execute_reply.started": "2025-02-10T15:51:11.113032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def custom_saving(model, epoch):\n",
    "    #Get optimizer and linear_rate_scheduler\n",
    "    opt = model.configure_optimizers()['optimizer']\n",
    "    lr_sched = model.configure_optimizers()['lr_scheduler']\n",
    "\n",
    "    #opt = model.configure_optimizers()\n",
    "    # Separate saving\n",
    "    torch.save(model.state_dict(), f\"/kaggle/working/model_{epoch}.pt\")\n",
    "    torch.save(opt.state_dict(), f\"/kaggle/working/optimizer_{epoch}.pt\")\n",
    "    torch.save(lr_sched.state_dict(), f\"/kaggle/working/lr_scheduler_{epoch}.pt\")\n",
    "\n",
    "    # All things together\n",
    "    checkpoint = { \n",
    "        'epoch': epoch,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': opt.state_dict(),\n",
    "        'lr_scheduler': lr_sched.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, f\"checkpoint_{epoch}.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load the CBMs\n",
    "\n",
    "Now that we have both the dataset and the model defined, we can train our CEM\n",
    "using Pytorch Lightning's wrappers for ease. This should be very simple via\n",
    "Pytorch Lightning's `Trainer` once the data has been generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:51:11.131664Z",
     "iopub.status.busy": "2025-02-10T15:51:11.131431Z",
     "iopub.status.idle": "2025-02-10T15:51:11.147544Z",
     "shell.execute_reply": "2025-02-10T15:51:11.146702Z",
     "shell.execute_reply.started": "2025-02-10T15:51:11.131636Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_model(typ):\n",
    "    cbm_model_new = ConceptBottleneckModel.load_from_checkpoint(\n",
    "        checkpoint_path=f\"models/{typ}.ckpt\", #might need to be changed to local\n",
    "        n_concepts=112,\n",
    "        n_tasks=200,\n",
    "        concept_loss_weight=yaml_config[\"shared_params\"][\"concept_loss_weight\"],\n",
    "        learning_rate=yaml_config[\"shared_params\"][\"learning_rate\"],  # The learning rate to use during training.\n",
    "        optimizer=\"sgd\",\n",
    "        c_extractor_arch=latent_code_generator_model, # Here we provide our generating function for the latent code generator model.\n",
    "        c2y_model=None,\n",
    "    )\n",
    "    \n",
    "    return cbm_model_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:51:11.148625Z",
     "iopub.status.busy": "2025-02-10T15:51:11.148363Z",
     "iopub.status.idle": "2025-02-10T15:51:16.043410Z",
     "shell.execute_reply": "2025-02-10T15:51:16.042716Z",
     "shell.execute_reply.started": "2025-02-10T15:51:11.148583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cbm_model_f = load_model(typ=\"cbm_buggy\")\n",
    "cbm_model_o = load_model(typ=\"cbm_oracle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Ranker model\n",
    "\n",
    "The ranker model has different configurations.\n",
    "- Config 1 (Ranker1 class), all four: $(x, c, w, y)$. Ranker $r(x, c_m(x), w_m, m(x))$.\n",
    "- Config 2 (Ranker2 class), without input image: $(c, w, y)$. Ranker $r(c_m(x), w_m, m(x))$.\n",
    "- Config 3 (Ranker3 class), without predicted label: $(x, c, w)$. Ranker $r(x, c_m(x), w_m)$.\n",
    "- Config 4 (Ranker4 class), only concepts and weights: $(c, w)$. Ranker $r(c_m(x), w_m)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config 1\n",
    "all four: $(x, c, w, y)$. Ranker $r(x, c_m(x), w_m, m(x))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:51:16.044303Z",
     "iopub.status.busy": "2025-02-10T15:51:16.044087Z",
     "iopub.status.idle": "2025-02-10T15:51:16.060939Z",
     "shell.execute_reply": "2025-02-10T15:51:16.059974Z",
     "shell.execute_reply.started": "2025-02-10T15:51:16.044282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src.rankers import Ranker1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:51:16.062518Z",
     "iopub.status.busy": "2025-02-10T15:51:16.061797Z",
     "iopub.status.idle": "2025-02-10T15:54:30.545956Z",
     "shell.execute_reply": "2025-02-10T15:54:30.545183Z",
     "shell.execute_reply.started": "2025-02-10T15:51:16.062487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCHS_NEW = 2\n",
    "\n",
    "ranker_config1 = Ranker1(cbm_model_f, cbm_model_o, lr=1e-5, margin=5)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",  # Change to \"cpu\" if you are not running on a GPU!\n",
    "    devices=\"auto\", \n",
    "    max_epochs=EPOCHS_NEW,  # The number of epochs we will train our model for #ORIGINAL 500\n",
    "    check_val_every_n_epoch=1,  # And how often we will check for validation metrics\n",
    "    logger=False,  # No logs to be dumped for this trainer\n",
    ")\n",
    "\n",
    "trainer.fit(ranker_config1, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:54:30.547138Z",
     "iopub.status.busy": "2025-02-10T15:54:30.546855Z",
     "iopub.status.idle": "2025-02-10T15:54:33.209877Z",
     "shell.execute_reply": "2025-02-10T15:54:33.208951Z",
     "shell.execute_reply.started": "2025-02-10T15:54:30.547110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Trainer saving\n",
    "trainer.save_checkpoint(f\"/kaggle/working/ranker_config1_{EPOCHS_NEW}.ckpt\")\n",
    "custom_saving(ranker_config1, EPOCHS_NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:54:33.211464Z",
     "iopub.status.busy": "2025-02-10T15:54:33.211132Z",
     "iopub.status.idle": "2025-02-10T15:54:36.503209Z",
     "shell.execute_reply": "2025-02-10T15:54:36.502008Z",
     "shell.execute_reply.started": "2025-02-10T15:54:33.211426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define input structure\n",
    "image_size = 3 * 299 * 299  # 268203\n",
    "concepts_size = 112\n",
    "weights_size = 22600\n",
    "labels_size = 200\n",
    "\n",
    "# Get weight vector\n",
    "W = ranker_config1.lay[0].weight.detach().cpu().numpy().flatten()\n",
    "total_features = image_size+concepts_size+weights_size+labels_size\n",
    "W = W[:total_features]\n",
    "\n",
    "# Compute absolute importance\n",
    "importance = np.abs(W)\n",
    "\n",
    "# Get indices of top 50 features\n",
    "top_k = 2500\n",
    "top_indices = np.argsort(-importance)[:top_k]  # Sort in descending order\n",
    "\n",
    "# Function to determine feature type\n",
    "def get_feature_category(index):\n",
    "    if index < image_size:\n",
    "        return \"Image\"\n",
    "    elif index < image_size + concepts_size:\n",
    "        return \"Concept\"\n",
    "    elif index < image_size + concepts_size + weights_size:\n",
    "        return \"Weight\"\n",
    "    else:\n",
    "        return \"Label\"\n",
    "\n",
    "counter = {\n",
    "    \"Image\":(0, 0),\n",
    "    \"Concept\":(0, 0),\n",
    "    \"Weight\":(0, 0),\n",
    "    \"Label\":(0, 0),\n",
    "}\n",
    "\n",
    "# Print categorized results\n",
    "print(f\"Top {top_k} Most Important Features by Category:\")\n",
    "for rank, idx in enumerate(top_indices):\n",
    "    category = get_feature_category(idx)\n",
    "    counter[category] = (counter[category][0]+1, counter[category][1]+importance[idx])\n",
    "    #print(f\"Rank {rank+1}: Feature {idx} ({category}) - Weight {W[idx]:.6f} (Importance: {importance[idx]:.6f})\")\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config 4\n",
    "only concepts and weights: $(c, w)$. Ranker $r(c_m(x), w_m)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rankers import Ranker4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:54:36.528774Z",
     "iopub.status.busy": "2025-02-10T15:54:36.528391Z",
     "iopub.status.idle": "2025-02-10T15:57:47.285409Z",
     "shell.execute_reply": "2025-02-10T15:57:47.284654Z",
     "shell.execute_reply.started": "2025-02-10T15:54:36.528741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCHS_NEW = 2 #same number of epochs\n",
    "\n",
    "ranker_config4 = Ranker4(cbm_model_f, cbm_model_o, lr=1e-5, margin=5)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",  # Change to \"cpu\" if you are not running on a GPU!\n",
    "    devices=\"auto\", \n",
    "    max_epochs=EPOCHS_NEW,  # The number of epochs we will train our model for #ORIGINAL 500\n",
    "    check_val_every_n_epoch=1,  # And how often we will check for validation metrics\n",
    "    logger=False,  # No logs to be dumped for this trainer\n",
    ")\n",
    "\n",
    "trainer.fit(ranker_config4, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:57:47.287201Z",
     "iopub.status.busy": "2025-02-10T15:57:47.286959Z",
     "iopub.status.idle": "2025-02-10T15:57:47.305203Z",
     "shell.execute_reply": "2025-02-10T15:57:47.304466Z",
     "shell.execute_reply.started": "2025-02-10T15:57:47.287179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define input structure\n",
    "concepts_size = 112\n",
    "weights_size = 22600\n",
    "\n",
    "# Get weight vector\n",
    "W = ranker_config4.lay[0].weight.detach().cpu().numpy().flatten()\n",
    "total_features = concepts_size+weights_size\n",
    "W = W[:total_features]\n",
    "\n",
    "# Compute absolute importance\n",
    "importance = np.abs(W)\n",
    "\n",
    "# Get indices of top 50 features\n",
    "top_k = 2500\n",
    "top_indices = np.argsort(-importance)[:top_k]  # Sort in descending order\n",
    "\n",
    "# Function to determine feature type\n",
    "def get_feature_category(index):\n",
    "    if index < concepts_size:\n",
    "        return \"Concept\"\n",
    "    else:\n",
    "        return \"Weight\"\n",
    "\n",
    "counter = {\n",
    "    \"Concept\":(0, 0),\n",
    "    \"Weight\":(0, 0),\n",
    "}\n",
    "\n",
    "# Print categorized results\n",
    "print(f\"Top {top_k} Most Important Features by Category:\")\n",
    "for rank, idx in enumerate(top_indices):\n",
    "    category = get_feature_category(idx)\n",
    "    counter[category] = (counter[category][0]+1, counter[category][1]+importance[idx])\n",
    "    #print(f\"Rank {rank+1}: Feature {idx} ({category}) - Weight {W[idx]:.6f} (Importance: {importance[idx]:.6f})\")\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:57:47.306528Z",
     "iopub.status.busy": "2025-02-10T15:57:47.306224Z",
     "iopub.status.idle": "2025-02-10T15:57:52.483974Z",
     "shell.execute_reply": "2025-02-10T15:57:52.482866Z",
     "shell.execute_reply.started": "2025-02-10T15:57:47.306499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Trainer saving\n",
    "trainer.save_checkpoint(f\"/kaggle/working/ranker_config4_{EPOCHS_NEW}.ckpt\")\n",
    "custom_saving(ranker_config4, EPOCHS_NEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config 3\n",
    "without predicted label: $(x, c, w)$. Ranker $r(x, c_m(x), w_m)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rankers import Ranker3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T15:57:52.513358Z",
     "iopub.status.busy": "2025-02-10T15:57:52.513033Z",
     "iopub.status.idle": "2025-02-10T16:01:05.736871Z",
     "shell.execute_reply": "2025-02-10T16:01:05.735882Z",
     "shell.execute_reply.started": "2025-02-10T15:57:52.513327Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCHS_NEW = 2 #same number of epochs\n",
    "\n",
    "ranker_config3 = Ranker3(cbm_model_f, cbm_model_o, lr=1e-5, margin=5)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",  # Change to \"cpu\" if you are not running on a GPU!\n",
    "    devices=\"auto\", \n",
    "    max_epochs=EPOCHS_NEW,  # The number of epochs we will train our model for #ORIGINAL 500\n",
    "    check_val_every_n_epoch=1,  # And how often we will check for validation metrics\n",
    "    logger=False,  # No logs to be dumped for this trainer\n",
    ")\n",
    "\n",
    "trainer.fit(ranker_config3, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T16:01:05.738221Z",
     "iopub.status.busy": "2025-02-10T16:01:05.737969Z",
     "iopub.status.idle": "2025-02-10T16:01:05.767867Z",
     "shell.execute_reply": "2025-02-10T16:01:05.767171Z",
     "shell.execute_reply.started": "2025-02-10T16:01:05.738198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define input structure\n",
    "image_size = 3 * 299 * 299  # 268203\n",
    "concepts_size = 112\n",
    "weights_size = 22600\n",
    "\n",
    "# Get weight vector\n",
    "W = ranker_config3.lay[0].weight.detach().cpu().numpy().flatten()\n",
    "total_features = image_size+concepts_size+weights_size\n",
    "W = W[:total_features]\n",
    "\n",
    "# Compute absolute importance\n",
    "importance = np.abs(W)\n",
    "\n",
    "# Get indices of top 50 features\n",
    "top_k = 2500\n",
    "top_indices = np.argsort(-importance)[:top_k]  # Sort in descending order\n",
    "\n",
    "# Function to determine feature type\n",
    "def get_feature_category(index):\n",
    "    if index < image_size:\n",
    "        return \"Image\"\n",
    "    elif index < image_size + concepts_size:\n",
    "        return \"Concept\"\n",
    "    else:\n",
    "        return \"Weight\"\n",
    "\n",
    "counter = {\n",
    "    \"Image\":(0, 0),\n",
    "    \"Concept\":(0, 0),\n",
    "    \"Weight\":(0, 0),\n",
    "}\n",
    "\n",
    "# Print categorized results\n",
    "print(f\"Top {top_k} Most Important Features by Category:\")\n",
    "for rank, idx in enumerate(top_indices):\n",
    "    category = get_feature_category(idx)\n",
    "    counter[category] = (counter[category][0]+1, counter[category][1]+importance[idx])\n",
    "    #print(f\"Rank {rank+1}: Feature {idx} ({category}) - Weight {W[idx]:.6f} (Importance: {importance[idx]:.6f})\")\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T16:01:05.768952Z",
     "iopub.status.busy": "2025-02-10T16:01:05.768663Z",
     "iopub.status.idle": "2025-02-10T16:01:10.555283Z",
     "shell.execute_reply": "2025-02-10T16:01:10.554327Z",
     "shell.execute_reply.started": "2025-02-10T16:01:05.768917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Trainer saving\n",
    "trainer.save_checkpoint(f\"/kaggle/working/ranker_config3_{EPOCHS_NEW}.ckpt\")\n",
    "custom_saving(ranker_config3, EPOCHS_NEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config 2\n",
    "without input image: $(c, w, y)$. Ranker $r(c_m(x), w_m, m(x))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T16:01:10.557163Z",
     "iopub.status.busy": "2025-02-10T16:01:10.556852Z",
     "iopub.status.idle": "2025-02-10T16:01:10.572546Z",
     "shell.execute_reply": "2025-02-10T16:01:10.570986Z",
     "shell.execute_reply.started": "2025-02-10T16:01:10.557133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src.rankers import Ranker2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T16:01:10.573968Z",
     "iopub.status.busy": "2025-02-10T16:01:10.573590Z",
     "iopub.status.idle": "2025-02-10T16:04:23.523526Z",
     "shell.execute_reply": "2025-02-10T16:04:23.522712Z",
     "shell.execute_reply.started": "2025-02-10T16:01:10.573932Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCHS_NEW = 2 #same number of epochs\n",
    "\n",
    "ranker_config2 = Ranker2(cbm_model_f, cbm_model_o, lr=1e-5, margin=5)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",  # Change to \"cpu\" if you are not running on a GPU!\n",
    "    devices=\"auto\", \n",
    "    max_epochs=EPOCHS_NEW,  # The number of epochs we will train our model for #ORIGINAL 500\n",
    "    check_val_every_n_epoch=1,  # And how often we will check for validation metrics\n",
    "    logger=False,  # No logs to be dumped for this trainer\n",
    ")\n",
    "\n",
    "trainer.fit(ranker_config2, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T16:04:23.524903Z",
     "iopub.status.busy": "2025-02-10T16:04:23.524633Z",
     "iopub.status.idle": "2025-02-10T16:04:23.538798Z",
     "shell.execute_reply": "2025-02-10T16:04:23.538070Z",
     "shell.execute_reply.started": "2025-02-10T16:04:23.524881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "concepts_size = 112\n",
    "weights_size = 22600\n",
    "labels_size = 200\n",
    "total_features = concepts_size + weights_size + labels_size  # Excluding bias\n",
    "\n",
    "# Get weight vector\n",
    "W = ranker_config2.lay[0].weight.detach().cpu().numpy().flatten()\n",
    "\n",
    "# Ignore bias term (last weight in W)\n",
    "W = W[:total_features]\n",
    "\n",
    "# Compute absolute importance\n",
    "importance = np.abs(W)\n",
    "\n",
    "# Get indices of top K features\n",
    "top_k = 2500\n",
    "top_indices = np.argsort(-importance)[:top_k]  # Sort in descending order\n",
    "\n",
    "# Function to determine feature type\n",
    "def get_feature_category(index):\n",
    "    if index < concepts_size:\n",
    "        return \"Concept\"\n",
    "    elif index < concepts_size + weights_size:\n",
    "        return \"Weight\"\n",
    "    else:\n",
    "        return \"Label\"\n",
    "\n",
    "counter = {\n",
    "    \"Concept\": (0, 0),\n",
    "    \"Weight\": (0, 0),\n",
    "    \"Label\": (0, 0),\n",
    "}\n",
    "\n",
    "# Print categorized results\n",
    "print(f\"Top {top_k} Most Important Features by Category:\")\n",
    "for rank, idx in enumerate(top_indices):\n",
    "    category = get_feature_category(idx)\n",
    "    counter[category] = (counter[category][0] + 1, counter[category][1] + importance[idx])\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T16:04:23.539693Z",
     "iopub.status.busy": "2025-02-10T16:04:23.539443Z",
     "iopub.status.idle": "2025-02-10T16:04:28.620799Z",
     "shell.execute_reply": "2025-02-10T16:04:28.619852Z",
     "shell.execute_reply.started": "2025-02-10T16:04:23.539671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Trainer saving\n",
    "trainer.save_checkpoint(f\"/kaggle/working/ranker_config2_{EPOCHS_NEW}.ckpt\")\n",
    "custom_saving(ranker_config2, EPOCHS_NEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T16:04:28.622899Z",
     "iopub.status.busy": "2025-02-10T16:04:28.622467Z",
     "iopub.status.idle": "2025-02-10T16:04:28.627450Z",
     "shell.execute_reply": "2025-02-10T16:04:28.626425Z",
     "shell.execute_reply.started": "2025-02-10T16:04:28.622869Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(dataloader, ranker):\n",
    "    #Now we are ready to generate the concept, label, and embedding predictions for\n",
    "    #the test set using our trained CEM:\n",
    "\n",
    "    # We will use a Trainer object to run inference in batches over our test\n",
    "    # dataset\n",
    "    trainer_inference = pl.Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        devices=\"auto\",\n",
    "        logger=False, # No logs to be dumped for this trainer\n",
    "    )\n",
    "    batch_results = trainer_inference.predict(ranker, dataloader)\n",
    "    average_loss = torch.mean(torch.stack(batch_results))\n",
    "    print(f\"The average test loss is: {average_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T16:04:28.628729Z",
     "iopub.status.busy": "2025-02-10T16:04:28.628423Z",
     "iopub.status.idle": "2025-02-10T16:05:00.533963Z",
     "shell.execute_reply": "2025-02-10T16:05:00.533098Z",
     "shell.execute_reply.started": "2025-02-10T16:04:28.628705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "evaluate_model(test_dl, ranker_config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T16:05:00.535224Z",
     "iopub.status.busy": "2025-02-10T16:05:00.534914Z",
     "iopub.status.idle": "2025-02-10T16:05:29.916726Z",
     "shell.execute_reply": "2025-02-10T16:05:29.915716Z",
     "shell.execute_reply.started": "2025-02-10T16:05:00.535194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "evaluate_model(test_dl, ranker_config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T16:05:29.918225Z",
     "iopub.status.busy": "2025-02-10T16:05:29.917915Z",
     "iopub.status.idle": "2025-02-10T16:05:59.531388Z",
     "shell.execute_reply": "2025-02-10T16:05:59.530507Z",
     "shell.execute_reply.started": "2025-02-10T16:05:29.918199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "evaluate_model(test_dl, ranker_config3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T16:05:59.532819Z",
     "iopub.status.busy": "2025-02-10T16:05:59.532459Z",
     "iopub.status.idle": "2025-02-10T16:06:28.953798Z",
     "shell.execute_reply": "2025-02-10T16:06:28.952705Z",
     "shell.execute_reply.started": "2025-02-10T16:05:59.532782Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "evaluate_model(test_dl, ranker_config4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2534241,
     "sourceId": 5140550,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6600121,
     "sourceId": 10658340,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6635574,
     "sourceId": 10713911,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 220467553,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 220470336,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 221545359,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
