{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is inspired by the work of CEM (Zarlenga et al. 2022) and CBM (Koh et al. 2020) papers. Please visit their GitHub repositories:\n",
    "[CEM GitHub](https://github.com/mateoespinosa/cem) and [CBM GitHub](https://github.com/yewsiang/ConceptBottleneck).\n",
    "\n",
    "# CBM: inspection - evaluating and manual inspection\n",
    "\n",
    "There are four main steps:\n",
    "1. Loading the dataset.\n",
    "2. Initializing a CBM with InceptionV3 vision backbone for the dataset.\n",
    "3. Load CBMs\n",
    "4. Inspect model\n",
    "5. Distribution plots\n",
    "6. Confusion matrix (not coded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data\n",
    "\n",
    "The first step is to load the data. The designed CBM class with the PyTorch Lightning Trainer takes in PyTorch DataLoader object.\n",
    "Furthermore, it needs to contain three elements (in the following order):\n",
    "1. the sample image, $\\mathbf{x}$\n",
    "2. the image label, $\\mathbf{y}$\n",
    "3. the concept labels, in binary format, $\\mathbf{c}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:09:46.679270Z",
     "iopub.status.busy": "2025-02-09T23:09:46.678936Z",
     "iopub.status.idle": "2025-02-09T23:09:46.683472Z",
     "shell.execute_reply": "2025-02-09T23:09:46.682549Z",
     "shell.execute_reply.started": "2025-02-09T23:09:46.679243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#from cub_data_module import *\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "import torchvision.models as models\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:09:48.198072Z",
     "iopub.status.busy": "2025-02-09T23:09:48.197756Z",
     "iopub.status.idle": "2025-02-09T23:09:57.709265Z",
     "shell.execute_reply": "2025-02-09T23:09:57.708567Z",
     "shell.execute_reply.started": "2025-02-09T23:09:48.198009Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#import sys #for Kaggle\n",
    "#sys.path.append(\"/kaggle/usr/lib/cub_data_module_confounded\") #for Kaggle\n",
    "\n",
    "import src.cub_data_module as cub_data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:10:02.204495Z",
     "iopub.status.busy": "2025-02-09T23:10:02.204008Z",
     "iopub.status.idle": "2025-02-09T23:10:02.212368Z",
     "shell.execute_reply": "2025-02-09T23:10:02.211410Z",
     "shell.execute_reply.started": "2025-02-09T23:10:02.204469Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _update_config_with_dataset(\n",
    "    config,\n",
    "    train_dl,\n",
    "    n_concepts,\n",
    "    n_tasks,\n",
    "    concept_map,\n",
    "):\n",
    "    config[\"n_concepts\"] = config.get(\n",
    "        \"n_concepts\",\n",
    "        n_concepts,\n",
    "    )\n",
    "    config[\"n_tasks\"] = config.get(\n",
    "        \"n_tasks\",\n",
    "        n_tasks,\n",
    "    )\n",
    "    config[\"concept_map\"] = config.get(\n",
    "        \"concept_map\",\n",
    "        concept_map,\n",
    "    )\n",
    "\n",
    "    task_class_weights = None\n",
    "\n",
    "    if config.get('use_task_class_weights', False):\n",
    "        logging.info(\n",
    "            f\"Computing task class weights in the training dataset with \"\n",
    "            f\"size {len(train_dl)}...\"\n",
    "        )\n",
    "        attribute_count = np.zeros((max(n_tasks, 2),))\n",
    "        samples_seen = 0\n",
    "        for i, data in enumerate(train_dl):\n",
    "            if len(data) == 2:\n",
    "                (_, (y, _)) = data\n",
    "            else:\n",
    "                (_, y, _) = data\n",
    "            if n_tasks > 1:\n",
    "                y = torch.nn.functional.one_hot(\n",
    "                    y,\n",
    "                    num_classes=n_tasks,\n",
    "                ).cpu().detach().numpy()\n",
    "            else:\n",
    "                y = torch.cat(\n",
    "                    [torch.unsqueeze(1 - y, dim=-1), torch.unsqueeze(y, dim=-1)],\n",
    "                    dim=-1,\n",
    "                ).cpu().detach().numpy()\n",
    "            attribute_count += np.sum(y, axis=0)\n",
    "            samples_seen += y.shape[0]\n",
    "        print(\"Class distribution is:\", attribute_count / samples_seen)\n",
    "        if n_tasks > 1:\n",
    "            task_class_weights = samples_seen / attribute_count - 1\n",
    "        else:\n",
    "            task_class_weights = np.array(\n",
    "                [attribute_count[0]/attribute_count[1]]\n",
    "            )\n",
    "    return task_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:10:02.213840Z",
     "iopub.status.busy": "2025-02-09T23:10:02.213562Z",
     "iopub.status.idle": "2025-02-09T23:10:02.227815Z",
     "shell.execute_reply": "2025-02-09T23:10:02.226933Z",
     "shell.execute_reply.started": "2025-02-09T23:10:02.213818Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _generate_dataset_and_update_config(\n",
    "    experiment_config\n",
    "):\n",
    "    if experiment_config.get(\"dataset_config\", None) is None:\n",
    "        raise ValueError(\n",
    "            \"A dataset_config must be provided for each experiment run!\"\n",
    "        )\n",
    "\n",
    "    dataset_config = experiment_config['dataset_config']\n",
    "    logging.debug(\n",
    "        f\"The dataset's root directory is {dataset_config.get('root_dir')}\"\n",
    "    )\n",
    "    intervention_config = experiment_config.get('intervention_config', {})\n",
    "    if dataset_config[\"dataset\"] == \"cub\":\n",
    "        data_module = cub_data_module\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset {dataset_config['dataset']}!\")\n",
    "\n",
    "    train_dl, val_dl, test_dl, imbalance, (n_concepts, n_tasks, concept_map) = \\\n",
    "        data_module.generate_data(\n",
    "            config=dataset_config,\n",
    "            seed=42,\n",
    "            output_dataset_vars=True,\n",
    "            root_dir=dataset_config.get('root_dir', None),\n",
    "            model_inspection=True,\n",
    "        )\n",
    "    # For now, we assume that all concepts have the same\n",
    "    # aquisition cost\n",
    "    acquisition_costs = None\n",
    "    if concept_map is not None:\n",
    "        intervened_groups = list(\n",
    "            range(\n",
    "                0,\n",
    "                len(concept_map) + 1,\n",
    "                intervention_config.get('intervention_freq', 1),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        intervened_groups = list(\n",
    "            range(\n",
    "                0,\n",
    "                n_concepts + 1,\n",
    "                intervention_config.get('intervention_freq', 1),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    task_class_weights = _update_config_with_dataset(\n",
    "        config=experiment_config,\n",
    "        train_dl=train_dl,\n",
    "        n_concepts=n_concepts,\n",
    "        n_tasks=n_tasks,\n",
    "        concept_map=concept_map,\n",
    "    )\n",
    "    return (\n",
    "        train_dl,\n",
    "        val_dl,\n",
    "        test_dl,\n",
    "        imbalance,\n",
    "        concept_map,\n",
    "        intervened_groups,\n",
    "        task_class_weights,\n",
    "        acquisition_costs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:10:02.229790Z",
     "iopub.status.busy": "2025-02-09T23:10:02.229525Z",
     "iopub.status.idle": "2025-02-09T23:10:02.265808Z",
     "shell.execute_reply": "2025-02-09T23:10:02.265241Z",
     "shell.execute_reply.started": "2025-02-09T23:10:02.229770Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "yaml_path = \"data/cub.yaml\" # for local development, might need to use whole path.\n",
    "\n",
    "with open(yaml_path, \"r\") as file:\n",
    "    yaml_config = yaml.safe_load(file)\n",
    "yaml_config[\"shared_params\"][\"dataset_config\"][\"root_dir\"] = \"/kaggle/input/cem-cub2000-filtered/\" #for Kaggle, replace this with locally downloaded folder.\n",
    "yaml_config[\"shared_params\"][\"dataset_config\"][\"num_workers\"] = 4 #change depending on resources available.\n",
    "yaml_config[\"shared_params\"][\"dataset_config\"][\"batch_size\"] = 64 #change depending on resources available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:10:02.266868Z",
     "iopub.status.busy": "2025-02-09T23:10:02.266641Z",
     "iopub.status.idle": "2025-02-09T23:10:03.858383Z",
     "shell.execute_reply": "2025-02-09T23:10:03.857471Z",
     "shell.execute_reply.started": "2025-02-09T23:10:02.266848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dl, val_dl, test_dl, imbalance, concept_map, intervened_groups, task_class_weights, acquisition_costs = _generate_dataset_and_update_config(yaml_config[\"shared_params\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create the CBM\n",
    "### Step 2.1 Define model for input to concepts\n",
    "We first need to define a architecture that will extract the concepts from the input image.\n",
    "\n",
    "For this, we used a pre-trained InceptionV3 model. We remove the last linear layer and make one that we can use for our task, so it is ready for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:10:03.859639Z",
     "iopub.status.busy": "2025-02-09T23:10:03.859321Z",
     "iopub.status.idle": "2025-02-09T23:10:03.864285Z",
     "shell.execute_reply": "2025-02-09T23:10:03.863432Z",
     "shell.execute_reply.started": "2025-02-09T23:10:03.859609Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def latent_code_generator_model(output_dim=112):\n",
    "    # Load pre-trained InceptionV3\n",
    "    inception = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)\n",
    "\n",
    "    # Remove auxiliary classifier (set to None)\n",
    "    inception.aux_logits = False  # Disable aux_logits\n",
    "    inception.AuxLogits = None  # Delete aux classifier branch\n",
    "\n",
    "    inception.fc = torch.nn.Linear(2048, output_dim)  # Replace classification layer with output_dim\n",
    "\n",
    "    return inception"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: define CBM model.\n",
    "We need to define the following:\n",
    "1. `n_concepts`: the number of concepts in the dataset (112).\n",
    "2. `n_tasks`: the number of output labels in the dataset (200).\n",
    "3. `concept_loss_weight`: the weight to use for the concept prediction loss during training of the CBM. Picked to be the same as the CEM paper.\n",
    "4. `learning_rate` and `optimizer`: to use during training. Optimizer is Adam by default, otherwise SGD.\n",
    "5. `c_extractor_arch`: the model architecture to use for going from the input space to the concepts.\n",
    "6. `c2y_model` and `c2y_layers`: the model architecture to use for going from the concepts to the labels. It can be directly the model, like c_extractor_arch or the layers as a list. We choose to do a simple linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:10:03.865239Z",
     "iopub.status.busy": "2025-02-09T23:10:03.864963Z",
     "iopub.status.idle": "2025-02-09T23:10:03.882266Z",
     "shell.execute_reply": "2025-02-09T23:10:03.881628Z",
     "shell.execute_reply.started": "2025-02-09T23:10:03.865219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src.utils_cbm import *\n",
    "from src.cbm import ConceptBottleneckModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load the CBMs\n",
    "\n",
    "Now that we have both the dataset and the model defined, we can train our CEM\n",
    "using Pytorch Lightning's wrappers for ease. This should be very simple via\n",
    "Pytorch Lightning's `Trainer` once the data has been generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:10:03.986668Z",
     "iopub.status.busy": "2025-02-09T23:10:03.986428Z",
     "iopub.status.idle": "2025-02-09T23:10:04.002855Z",
     "shell.execute_reply": "2025-02-09T23:10:04.002221Z",
     "shell.execute_reply.started": "2025-02-09T23:10:03.986635Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_model(typ):\n",
    "    cbm_model_new = ConceptBottleneckModel.load_from_checkpoint(\n",
    "        checkpoint_path=f\"models/{typ}.ckpt\", #might need to be changed to local\n",
    "        n_concepts=112,\n",
    "        n_tasks=200,\n",
    "        concept_loss_weight=yaml_config[\"shared_params\"][\"concept_loss_weight\"],\n",
    "        learning_rate=yaml_config[\"shared_params\"][\"learning_rate\"],  # The learning rate to use during training.\n",
    "        optimizer=\"sgd\",\n",
    "        c_extractor_arch=latent_code_generator_model, # Here we provide our generating function for the latent code generator model.\n",
    "        c2y_model=None,\n",
    "    )\n",
    "    \n",
    "    return cbm_model_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:10:04.003785Z",
     "iopub.status.busy": "2025-02-09T23:10:04.003598Z",
     "iopub.status.idle": "2025-02-09T23:10:10.386677Z",
     "shell.execute_reply": "2025-02-09T23:10:10.385734Z",
     "shell.execute_reply.started": "2025-02-09T23:10:04.003768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cbm_model_f = load_model(typ=\"cbm_buggy\")\n",
    "cbm_model_o = load_model(typ=\"cbm_oracle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:10:10.417144Z",
     "iopub.status.busy": "2025-02-09T23:10:10.416857Z",
     "iopub.status.idle": "2025-02-09T23:10:34.027614Z",
     "shell.execute_reply": "2025-02-09T23:10:34.026440Z",
     "shell.execute_reply.started": "2025-02-09T23:10:10.417115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Before anything, however, let's get the underlying numpy arrays of our\n",
    "# test dataset as they will be easier to work with\n",
    "x_test, y_test, c_test = [], [], []\n",
    "for (x, y, c) in tqdm(test_dl):\n",
    "    x_test.append(x)\n",
    "    y_test.append(y)\n",
    "    c_test.append(c)\n",
    "x_test = np.concatenate(x_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "c_test = np.concatenate(c_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:10:34.031543Z",
     "iopub.status.busy": "2025-02-09T23:10:34.031279Z",
     "iopub.status.idle": "2025-02-09T23:10:34.038158Z",
     "shell.execute_reply": "2025-02-09T23:10:34.037177Z",
     "shell.execute_reply.started": "2025-02-09T23:10:34.031522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(dataloader, cbm, x_test, y_test, c_test):\n",
    "    #Now we are ready to generate the concept, label, and embedding predictions for\n",
    "    #the test set using our trained CEM:\n",
    "\n",
    "    # We will use a Trainer object to run inference in batches over our test\n",
    "    # dataset\n",
    "    trainer_inference = pl.Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        devices=\"auto\",\n",
    "        logger=False, # No logs to be dumped for this trainer\n",
    "    )\n",
    "    batch_results = trainer_inference.predict(cbm, dataloader)\n",
    "    \n",
    "    # Then we combine all results into numpy arrays by joining over the batch\n",
    "    # dimension\n",
    "    c_pred = np.concatenate(\n",
    "        list(map(lambda x: x[0].detach().cpu().numpy(), batch_results)),\n",
    "        axis=0,\n",
    "    )\n",
    "    c_embs = np.concatenate(\n",
    "        list(map(lambda x: x[1].detach().cpu().numpy(), batch_results)),\n",
    "        axis=0,\n",
    "    )\n",
    "    # Reshape them so that we have embeddings (batch_size, k, emb_size)\n",
    "    c_embs = np.reshape(c_embs, (c_test.shape[0], c_test.shape[1], -1))\n",
    "    \n",
    "    y_pred = np.concatenate(\n",
    "        list(map(lambda x: x[2].detach().cpu().numpy(), batch_results)),\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    ##And compute all the metrics of interest:\n",
    "    # To match the dimensions of y_pred (5794, 200), and y_test (5794,):\n",
    "    # We need to apply a softmax layer to get the class probabilities\n",
    "    y_prob = softmax(y_pred, axis=1)\n",
    "    \n",
    "    # Then we get the highest probability for the classes\n",
    "    y_pred_classes = np.argmax(y_prob, axis=1)  # Shape (5794,)\n",
    "\n",
    "\n",
    "\n",
    "    ##########\n",
    "    ## Compute test task accuracy\n",
    "    ##########\n",
    "    task_accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    print(f\"Our CBM's test task accuracy is {task_accuracy*100:.2f}%\")\n",
    "\n",
    "    ##########\n",
    "    ## Compute test concept AUC\n",
    "    ##########\n",
    "    concept_auc = roc_auc_score(c_test, c_pred)\n",
    "    print(f\"Our CBM's test concept AUC is {concept_auc*100:.2f}%\")\n",
    "\n",
    "    return y_pred_classes, c_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:10:34.039363Z",
     "iopub.status.busy": "2025-02-09T23:10:34.039043Z",
     "iopub.status.idle": "2025-02-09T23:12:19.079587Z",
     "shell.execute_reply": "2025-02-09T23:12:19.078709Z",
     "shell.execute_reply.started": "2025-02-09T23:10:34.039321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred_classes, c_pred = evaluate_model(test_dl, cbm_model_o, x_test, y_test, c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:12:19.080921Z",
     "iopub.status.busy": "2025-02-09T23:12:19.080586Z",
     "iopub.status.idle": "2025-02-09T23:12:19.085988Z",
     "shell.execute_reply": "2025-02-09T23:12:19.085211Z",
     "shell.execute_reply.started": "2025-02-09T23:12:19.080891Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def concepti(c_sem):\n",
    "    # Get indices of True values\n",
    "    indices = torch.nonzero((torch.tensor(c_sem) > 0.5).float(), as_tuple=True)\n",
    "    #print(indices[1].tolist())\n",
    "\n",
    "    #print(indices)\n",
    "\n",
    "    concepts_str_list = []\n",
    "    \n",
    "    for concept in indices[0].tolist():\n",
    "        selected_concept = cub_data_module.SELECTED_CONCEPTS[concept]\n",
    "        concept_str = cub_data_module.CONCEPT_SEMANTICS[selected_concept]\n",
    "        concepts_str_list.append(concept_str)\n",
    "    return concepts_str_list\n",
    "\n",
    "def plot_image2(x_org):\n",
    "    # Display image\n",
    "    #image_tensor = x_org.squeeze(0)# Remove the batch dimension\n",
    "    \n",
    "    #transform = transforms.ToPILImage()# Convert the tensor to a PIL image\n",
    "    #image = transform(x_org)\n",
    "    \n",
    "    plt.imshow(x_org)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:42:44.791139Z",
     "iopub.status.busy": "2025-02-09T23:42:44.790719Z",
     "iopub.status.idle": "2025-02-09T23:42:46.122623Z",
     "shell.execute_reply": "2025-02-09T23:42:46.121743Z",
     "shell.execute_reply.started": "2025-02-09T23:42:44.791105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Let's inspect the model by looking into 25 instances of the test set.\n",
    "\n",
    "#Pick 10 random instances in the set\n",
    "random_indices = np.random.choice(len(y_test), 10, replace=False)\n",
    "\n",
    "for index in random_indices:\n",
    "    plot_image2(np.transpose(x_test[index], (1, 2, 0)))\n",
    "    print(\"y_p:\", y_pred_classes[index])\n",
    "    print(\"y_r:\", y_test[index])\n",
    "    print()\n",
    "\n",
    "    print('c_p:')\n",
    "    print(\"\\n\".join(concepti(c_pred[index])))\n",
    "    #print('c_r':, c_test[i])\n",
    "\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:12:19.269858Z",
     "iopub.status.busy": "2025-02-09T23:12:19.269538Z",
     "iopub.status.idle": "2025-02-09T23:14:06.140644Z",
     "shell.execute_reply": "2025-02-09T23:14:06.139866Z",
     "shell.execute_reply.started": "2025-02-09T23:12:19.269827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred_classes_f, c_pred_f = evaluate_model(test_dl, cbm_model_f, x_test, y_test, c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:42:58.640371Z",
     "iopub.status.busy": "2025-02-09T23:42:58.639938Z",
     "iopub.status.idle": "2025-02-09T23:42:59.981705Z",
     "shell.execute_reply": "2025-02-09T23:42:59.980745Z",
     "shell.execute_reply.started": "2025-02-09T23:42:58.640339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For the same random matches, let's see what the buggy model predicts\n",
    "for index in random_indices:\n",
    "    plot_image2(np.transpose(x_test[index], (1, 2, 0)))\n",
    "    print(\"y_p:\", y_pred_classes_f[index])\n",
    "    print(\"y_r:\", y_test[index])\n",
    "    print()\n",
    "\n",
    "    print('c_p:')\n",
    "    print(\"\\n\".join(concepti(c_pred_f[index])))\n",
    "    #print('c_r':, c_test[i])\n",
    "\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: distribution plots\n",
    "There is a strong suspicion that the buggy model is overclassifying a certain class. So this is investigation at this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T23:18:54.839533Z",
     "iopub.status.busy": "2025-02-09T23:18:54.839140Z",
     "iopub.status.idle": "2025-02-09T23:18:56.848659Z",
     "shell.execute_reply": "2025-02-09T23:18:56.847655Z",
     "shell.execute_reply.started": "2025-02-09T23:18:54.839506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate the distributions\n",
    "oracle_distribution = Counter(y_pred_classes)\n",
    "real_distribution = Counter(y_test)\n",
    "buggy_distribution = Counter(y_pred_classes_f)\n",
    "\n",
    "# Create a list of all unique classes\n",
    "all_classes = list(set(oracle_distribution.keys()).union(set(real_distribution.keys())).union(set(buggy_distribution.keys())))\n",
    "\n",
    "# Create lists for the counts of each class in each distribution\n",
    "oracle_counts = [oracle_distribution.get(cls, 0) for cls in all_classes]\n",
    "real_counts = [real_distribution.get(cls, 0) for cls in all_classes]\n",
    "buggy_counts = [buggy_distribution.get(cls, 0) for cls in all_classes]\n",
    "\n",
    "# Plot the oracle distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(all_classes, oracle_counts, color='blue', label='Oracle distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Oracle Distribution of Classes')\n",
    "plt.legend()\n",
    "plt.savefig('oracle_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot the real distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(all_classes, real_counts, color='green', label='Real distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Real Distribution of Classes')\n",
    "plt.legend()\n",
    "plt.savefig('real_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot the buggy distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(all_classes, buggy_counts, color='red', label='Buggy distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Buggy Distribution of Classes')\n",
    "plt.legend()\n",
    "plt.savefig('buggy_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6:\n",
    "An alternative idea to the distribution plot would be to plot a confusion matrix. However, as there are 200 classes, it's very difficult to get them all plotted and the plots might become cluttered."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2534241,
     "sourceId": 5140550,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6600121,
     "sourceId": 10658340,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6635574,
     "sourceId": 10706828,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 220467553,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 220470336,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 221545359,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
